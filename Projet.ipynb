{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e83e11-3292-4463-be13-c8ef45800b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collecte de données\n",
    "\n",
    "Vous devez collecter et télécharger un ensemble d'images. Vous avez les tâches suivantes à programmer, en automatisant le processus autant que possible :\n",
    "\n",
    "1.  Créer un dossier appelé *images*.\n",
    "2.  Télécharger les images sous licence ouverte dans le dossier *images* (minimum 100\n",
    "    images).\n",
    "3.  Enregistrez les métadonnées de chaque image comme la taille de l'image, le format de l'image (.jpeg,\n",
    "    .png, etc.), l'orientation de l'image (paysage, portrait, carré, etc.),\n",
    "    date de création, modèle d'appareil photo, etc. dans un ou plusieurs fichiers JSON. Vous pouvez utiliser les informations [Exif](https://en.wikipedia.org/wiki/Exif) présentes dans les fichiers d'images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51288d2c-8b6a-4ec2-9a9f-3a0a8fe8209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dossier 'images' a été créé avec succès.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Spécifiez le chemin du dossier que vous souhaitez créer\n",
    "dossier = 'images'\n",
    "\n",
    "# Créez le dossier\n",
    "os.makedirs(dossier, exist_ok=True)\n",
    "\n",
    "print(f\"Le dossier '{dossier}' a été créé avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6582d384-85e3-4da2-8175-c8c594c0ca35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SPARQLWrapper in /home/moha/Documents/CPE/S8/Data mining - machine learning/Machine Learning PROJET/MachineLearning/env/lib/python3.12/site-packages (2.0.0)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in /home/moha/Documents/CPE/S8/Data mining - machine learning/Machine Learning PROJET/MachineLearning/env/lib/python3.12/site-packages (from SPARQLWrapper) (7.1.3)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/moha/Documents/CPE/S8/Data mining - machine learning/Machine Learning PROJET/MachineLearning/env/lib/python3.12/site-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812c8ba3-694c-442c-a0ed-2a5b3e4d1e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Téléchargé : image_6.jpg\n",
      "✅ Téléchargé : image_7.jpg\n",
      "✅ Téléchargé : image_5.jpg\n",
      "✅ Téléchargé : image_1.jpg\n",
      "✅ Téléchargé : image_2.jpg\n",
      "✅ Téléchargé : image_3.jpg\n",
      "✅ Téléchargé : image_8.jpg\n",
      "✅ Téléchargé : image_10.jpg\n",
      "✅ Téléchargé : image_9.jpg\n",
      "✅ Téléchargé : image_4.jpg\n",
      "✅ Téléchargé : image_11.jpg\n",
      "✅ Téléchargé : image_12.jpg\n",
      "✅ Téléchargé : image_20.jpg\n",
      "✅ Téléchargé : image_13.jpg\n",
      "✅ Téléchargé : image_21.jpg\n",
      "✅ Téléchargé : image_22.jpg\n",
      "✅ Téléchargé : image_24.jpg\n",
      "✅ Téléchargé : image_14.jpg\n",
      "✅ Téléchargé : image_19.jpg\n",
      "✅ Téléchargé : image_18.jpg\n",
      "✅ Téléchargé : image_23.jpg\n",
      "✅ Téléchargé : image_16.jpg\n",
      "✅ Téléchargé : image_25.jpg\n",
      "✅ Téléchargé : image_30.jpg\n",
      "✅ Téléchargé : image_27.jpg\n",
      "✅ Téléchargé : image_17.jpg\n",
      "✅ Téléchargé : image_32.jpg\n",
      "✅ Téléchargé : image_31.jpg\n",
      "✅ Téléchargé : image_15.jpg\n",
      "✅ Téléchargé : image_26.jpg\n",
      "✅ Téléchargé : image_34.jpg\n",
      "✅ Téléchargé : image_35.jpg\n",
      "✅ Téléchargé : image_36.jpg\n",
      "✅ Téléchargé : image_39.jpg\n",
      "✅ Téléchargé : image_40.jpg\n",
      "✅ Téléchargé : image_37.jpg\n",
      "✅ Téléchargé : image_28.jpg\n",
      "✅ Téléchargé : image_41.jpg\n",
      "✅ Téléchargé : image_42.jpg\n",
      "✅ Téléchargé : image_47.jpg\n",
      "✅ Téléchargé : image_49.jpg\n",
      "✅ Téléchargé : image_29.jpg\n",
      "✅ Téléchargé : image_48.jpg\n",
      "✅ Téléchargé : image_46.jpg\n",
      "✅ Téléchargé : image_44.jpg\n",
      "✅ Téléchargé : image_45.jpg\n",
      "✅ Téléchargé : image_43.jpg\n",
      "✅ Téléchargé : image_33.jpg\n",
      "✅ Téléchargé : image_50.jpg\n",
      "✅ Téléchargé : image_54.jpg\n",
      "✅ Téléchargé : image_55.jpg\n",
      "✅ Téléchargé : image_59.jpg\n",
      "✅ Téléchargé : image_56.jpg\n",
      "✅ Téléchargé : image_58.jpg\n",
      "✅ Téléchargé : image_57.jpg\n",
      "✅ Téléchargé : image_53.jpg\n",
      "✅ Téléchargé : image_60.jpg\n",
      "✅ Téléchargé : image_62.jpg\n",
      "✅ Téléchargé : image_38.jpg\n",
      "✅ Téléchargé : image_63.jpg\n",
      "✅ Téléchargé : image_61.jpg\n",
      "✅ Téléchargé : image_67.jpg\n",
      "✅ Téléchargé : image_68.jpg\n",
      "✅ Téléchargé : image_51.jpg\n",
      "✅ Téléchargé : image_65.jpg\n",
      "✅ Téléchargé : image_64.jpg\n",
      "✅ Téléchargé : image_69.jpg\n",
      "✅ Téléchargé : image_72.jpg\n",
      "✅ Téléchargé : image_70.jpg\n",
      "✅ Téléchargé : image_52.jpg\n",
      "✅ Téléchargé : image_74.jpg\n",
      "✅ Téléchargé : image_66.jpg\n",
      "✅ Téléchargé : image_73.jpg\n",
      "✅ Téléchargé : image_75.jpg\n",
      "✅ Téléchargé : image_78.jpg\n",
      "✅ Téléchargé : image_77.jpg\n",
      "✅ Téléchargé : image_76.jpg\n",
      "✅ Téléchargé : image_83.jpg\n",
      "✅ Téléchargé : image_82.jpg\n",
      "✅ Téléchargé : image_81.jpg\n",
      "✅ Téléchargé : image_86.jpg\n",
      "✅ Téléchargé : image_87.jpg\n",
      "✅ Téléchargé : image_91.jpg\n",
      "✅ Téléchargé : image_90.jpg\n",
      "✅ Téléchargé : image_71.jpg\n",
      "✅ Téléchargé : image_79.jpg\n",
      "✅ Téléchargé : image_92.jpg\n",
      "✅ Téléchargé : image_85.jpg\n",
      "✅ Téléchargé : image_94.jpg\n",
      "✅ Téléchargé : image_93.jpg\n",
      "✅ Téléchargé : image_84.jpg\n",
      "✅ Téléchargé : image_95.jpg\n",
      "✅ Téléchargé : image_97.jpg\n",
      "✅ Téléchargé : image_80.jpg\n",
      "✅ Téléchargé : image_96.jpg\n",
      "✅ Téléchargé : image_89.jpg\n",
      "✅ Téléchargé : image_99.jpg\n",
      "✅ Téléchargé : image_98.jpg\n",
      "✅ Téléchargé : image_100.jpg\n",
      "✅ Téléchargé : image_88.jpg\n",
      "✅ Tous les téléchargements sont terminés !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from urllib.parse import urlparse\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Initialiser le wrapper SPARQL\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "# Définir la requête SPARQL pour obtenir des images de monuments\n",
    "sparql.setQuery(\"\"\"\n",
    "SELECT ?monument ?monumentLabel ?image WHERE {\n",
    "  ?monument wdt:P31 wd:Q839954.  # Monument\n",
    "  ?monument wdt:P18 ?image.      # Image\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "}\n",
    "LIMIT 100\n",
    "\"\"\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "try:\n",
    "    # Exécuter la requête et récupérer les résultats en JSON\n",
    "    results = sparql.query().convert()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de l'exécution de la requête SPARQL : {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Liste des images à télécharger avec des indices de 1 à 100\n",
    "images = [(i + 1, result[\"image\"][\"value\"]) for i, result in enumerate(results[\"results\"][\"bindings\"])]\n",
    "\n",
    "# Définition d'un User-Agent personnalisé\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"MonScript/1.0 (mailto:mohamedguef@gmail.com)\"  # Remplace par ton email pour respecter la politique\n",
    "}\n",
    "\n",
    "def download_image(data):\n",
    "    index, image_url = data\n",
    "    try:\n",
    "        # Nom fixe sous le format image_1.jpg, image_2.jpg, ..., image_100.jpg\n",
    "        image_name = f\"image_{index}.jpg\"\n",
    "        image_path = os.path.join(IMAGE_DIR, image_name)\n",
    "\n",
    "        # Télécharger l'image avec un User-Agent correct\n",
    "        response = requests.get(image_url, headers=HEADERS, timeout=10)\n",
    "        response.raise_for_status()  # Vérifie si la requête a réussi\n",
    "        \n",
    "        # Sauvegarder l'image\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        print(f\"✅ Téléchargé : {image_name}\")\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"⚠️ Erreur lors du téléchargement de {image_url} : {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Erreur inattendue : {e}\")\n",
    "\n",
    "# Téléchargement des images en parallèle\n",
    "MAX_THREADS = 10  # Ajuste ce nombre en fonction de ta connexion et des performances\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "    executor.map(download_image, images)\n",
    "\n",
    "print(\"✅ Tous les téléchargements sont terminés !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8340020b-de37-4dff-bac1-aa42b42e5ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /home/moha/Documents/CPE/S8/Data mining - machine learning/Machine Learning PROJET/MachineLearning/env/lib/python3.12/site-packages (11.1.0)\n",
      "Collecting ExifRead\n",
      "  Downloading ExifRead-3.0.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Downloading ExifRead-3.0.0-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: ExifRead\n",
      "Successfully installed ExifRead-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow ExifRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebbcd039-d958-48b1-9440-41acf98b251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m789.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eda7863-b996-4635-8b4b-17c1b7fd28c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Possibly corrupted field ImageDescription in Image IFD  | 0/100 [00:00<?, ?it/s]\n",
      "Possibly corrupted field Artist in Image IFD\n",
      "Possibly corrupted field Copyright in Image IFD\n",
      "📷 Extraction des métadonnées: 100%|████████| 100/100 [00:00<00:00, 2432.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Image illisible : image_91.jpg (corrompue ou format inconnu)\n",
      "⚠️ Image illisible : image_92.jpg (corrompue ou format inconnu)\n",
      "⚠️ Image illisible : image_93.jpg (corrompue ou format inconnu)\n",
      "⚠️ Image illisible : image_94.jpg (corrompue ou format inconnu)\n",
      "⚠️ Image illisible : image_95.jpg (corrompue ou format inconnu)\n",
      "✅ Métadonnées enregistrées dans 'images/metadata.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import exifread\n",
    "from tqdm import tqdm  # Barre de progression\n",
    "\n",
    "# Définir le dossier des images et le fichier de sortie JSON\n",
    "IMAGE_DIR = \"images\"\n",
    "METADATA_FILE = os.path.join(IMAGE_DIR, \"metadata.json\")\n",
    "\n",
    "# Vérifier que le dossier \"images\" existe\n",
    "if not os.path.exists(IMAGE_DIR):\n",
    "    print(f\"⚠️ Dossier '{IMAGE_DIR}' introuvable. Vérifiez que les images sont bien téléchargées.\")\n",
    "    exit(1)\n",
    "\n",
    "# Liste pour stocker les métadonnées de toutes les images\n",
    "metadata_list = []\n",
    "\n",
    "# Liste des fichiers images triés\n",
    "image_files = sorted([f for f in os.listdir(IMAGE_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "# Parcourir les images et extraire les métadonnées\n",
    "for image_name in tqdm(image_files, desc=\"📷 Extraction des métadonnées\"):\n",
    "    image_path = os.path.join(IMAGE_DIR, image_name)\n",
    "\n",
    "    try:\n",
    "        # Vérifier si l'image est corrompue en tentant de l'ouvrir\n",
    "        with Image.open(image_path) as img:\n",
    "            img.verify()  # Vérifie l'intégrité de l'image sans la charger\n",
    "            img = Image.open(image_path)  # Recharge l'image pour la lecture des métadonnées\n",
    "            width, height = img.size\n",
    "            format_ = img.format\n",
    "            orientation = 'Portrait' if height > width else 'Paysage' if width > height else 'Carré'\n",
    "\n",
    "        # Vérifier si c'est un PNG (pas d'Exif)\n",
    "        if format_.upper() == \"PNG\":\n",
    "            exif_data = \"Non disponible (format PNG)\"\n",
    "        else:\n",
    "            # Extraire les métadonnées Exif avec exifread\n",
    "            with open(image_path, 'rb') as f:\n",
    "                tags = exifread.process_file(f, stop_tag=\"EXIF DateTimeOriginal\", details=False)\n",
    "\n",
    "            # Filtrer les champs problématiques\n",
    "            exif_data = {\n",
    "                \"Date de création\": str(tags.get(\"EXIF DateTimeOriginal\", \"Inconnu\")),\n",
    "                \"Modèle d'appareil\": str(tags.get(\"Image Model\", \"Inconnu\")),\n",
    "                \"Marque d'appareil\": str(tags.get(\"Image Make\", \"Inconnu\")),\n",
    "                \"ISO\": str(tags.get(\"EXIF ISOSpeedRatings\", \"Inconnu\")),\n",
    "                \"Temps d'exposition\": str(tags.get(\"EXIF ExposureTime\", \"Inconnu\")),\n",
    "                \"Ouverture (f)\": str(tags.get(\"EXIF FNumber\", \"Inconnu\")),\n",
    "                \"Longueur focale\": str(tags.get(\"EXIF FocalLength\", \"Inconnu\")),\n",
    "                \"GPS Latitude\": str(tags.get(\"GPS GPSLatitude\", \"Non disponible\")),\n",
    "                \"GPS Longitude\": str(tags.get(\"GPS GPSLongitude\", \"Non disponible\")),\n",
    "            }\n",
    "\n",
    "            # Supprimer les champs corrompus (évite les erreurs \"Possibly corrupted field\")\n",
    "            exif_data = {key: value for key, value in exif_data.items() if \"Possibly corrupted\" not in value}\n",
    "\n",
    "        # Ajouter les métadonnées à la liste\n",
    "        metadata_list.append({\n",
    "            'Nom du fichier': image_name,\n",
    "            'Taille': {'Largeur': width, 'Hauteur': height},\n",
    "            'Format': format_,\n",
    "            'Orientation': orientation,\n",
    "            'Exif': exif_data\n",
    "        })\n",
    "\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"⚠️ Image illisible : {image_name} (corrompue ou format inconnu)\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Erreur inattendue sur {image_name} : {e}\")\n",
    "\n",
    "# Enregistrer toutes les métadonnées dans un fichier JSON\n",
    "try:\n",
    "    with open(METADATA_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata_list, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"✅ Métadonnées enregistrées dans '{METADATA_FILE}'\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de l'enregistrement du fichier JSON : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af34f35-738a-4d33-9785-a89157046b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
